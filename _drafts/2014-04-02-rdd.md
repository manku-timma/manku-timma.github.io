---
layout: post
title:  "Understanding RDD"
date:   2014-04-02 12:00:00
tags: apache spark, rdd
---

I am reading the [paper][rdd] on Resilient Distributed Datasets (RDD) which
are the basic abstraction in Apache Spark. Below is a digest.

RDD is a distributed memory abstraction. Another one is distributed shared
memory (which can be implemented as a distributed hash table or as a
distributed database for instance).

- RDDs focus on bulk operations for writes. This allows more efficient fault
  tolerance.
- RDDs allow multiple tasks to work on the same data. (What about streaming?)

[rdd]: http://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf
